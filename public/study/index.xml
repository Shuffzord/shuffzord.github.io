<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Studies on Principles</title>
    <link>http://localhost:1313/study/</link>
    <description>Recent content in Studies on Principles</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Tue, 18 Jan 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/study/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Machine Learning</title>
      <link>http://localhost:1313/study/machinelearning/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/study/machinelearning/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#machine-learning-basics&#34;&gt;Machine Learning Basics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#algorithms&#34;&gt;Algorithms&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#problems&#34;&gt;Problems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#model--cost-function&#34;&gt;Model &amp;amp; Cost Function&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#cost-function-intuition-i&#34;&gt;Cost Function Intuition I&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#cost-function---intuition-ii&#34;&gt;Cost Function - Intuition II&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#parameter-learning&#34;&gt;Parameter Learning&lt;/a&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#gradient-descent&#34;&gt;Gradient Descent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#gradient-descent-intuition&#34;&gt;Gradient Descent Intuition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#multiple-features&#34;&gt;Multiple Features&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/study/machinelearning/#normal-equation&#34;&gt;Normal Equation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;machine-learning-basics&#34;&gt;Machine Learning Basics&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;A computer program is said to learn from &lt;strong&gt;experience E&lt;/strong&gt; with respect to some &lt;strong&gt;task T&lt;/strong&gt; and some &lt;strong&gt;performance measure P&lt;/strong&gt;, if its performance on T as measured by P, improves with experience E&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-Example:&#34; data-lang=&#34;Example:&#34;&gt;E = the experience of playing many games of checkers&#xD;&#xA;T = the task of playing checkers.&#xD;&#xA;P = the probability that the program will win the next game&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;algorithms&#34;&gt;Algorithms&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Supervised Learning&#xA;We give the algorithm &amp;lsquo;right answer&amp;rsquo; to learn&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised learning&#xA;Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don&amp;rsquo;t necessarily know the effect of the variables.&#xA;We can derive this structure by clustering the data based on relationships among the variables in the data.&#xA;With unsupervised learning there is no feedback based on the prediction results.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;problems&#34;&gt;Problems&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Regression: Predict continuous valued output&lt;/li&gt;&#xA;&lt;li&gt;Classification: Discrete valued output (0,1,&amp;hellip;can be more options than two)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;model--cost-function&#34;&gt;Model &amp;amp; Cost Function&lt;/h2&gt;&#xA;&lt;p&gt;To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. Seen pictorially, the process is therefore like this:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
